{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3038f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5da2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from pathlib import Path\n",
    "\n",
    "base_folder = Path('.')\n",
    "job_kwargs = {'n_jobs': -1, 'progress_bar' :True, 'chunk_duration' : '1s', 'verbose': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0df0ad-4e1e-4faf-96be-b3e896bdcf64",
   "metadata": {},
   "source": [
    "## We load all the recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646a8510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA21030_v270224_DIV20_MOCK_basal.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA21030_v270224_DIV20_MOCK_postT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA21030_v270224_DIV20_MOCK_preT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_basal.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_postT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_preT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22871_v270224_DIV20_BIN1iso1_basal.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22871_v270224_DIV20_BIN1iso1_postT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22871_v270224_DIV20_BIN1iso1_preT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22885_v270224_DIV20_BIN1iso1_basal.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22885_v270224_DIV20_BIN1iso1_postT.h5\n",
      "experiments/BIN1 SET3/2024-03-20_CG_BIN1exp3_MEA22885_v270224_DIV20_BIN1iso1_preT.h5\n",
      "We have loaded 12 recordings\n"
     ]
    }
   ],
   "source": [
    "import os, h5py\n",
    "import pandas as pd\n",
    "from tools import load_experiment, infer_boundaries\n",
    "\n",
    "recordings = {}\n",
    "remove_center = True\n",
    "\n",
    "for folder in os.listdir(base_folder / \"experiments\"):\n",
    "    datapath = base_folder / \"experiments\" / folder\n",
    "\n",
    "    for file in os.listdir(datapath):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            data = pd.read_excel(datapath / file)\n",
    "            data.to_csv(str(datapath / file).replace('.xlsx', '.csv'))\n",
    "    \n",
    "    for file in os.listdir(datapath):\n",
    "        if file.endswith(\".h5\"):\n",
    "            key, ext = os.path.splitext(file)\n",
    "            try:\n",
    "                recordings[key] = load_experiment(file, datapath, remove_center)\n",
    "            except Exception:\n",
    "                print('Problem while loading', datapath, file)\n",
    "print('We have loaded', len(recordings), 'recordings')\n",
    "for key in recordings.keys():\n",
    "    recordings[key]['filtered'] = si.bandpass_filter(recordings[key]['raw'], freq_min= 150, freq_max= 7000, ftype= \"bessel\", filter_order= 2)\n",
    "    recordings[key]['filtered'] = si.common_reference(recordings[key]['filtered'])\n",
    "#    recordings[key]['filtered'] = si.zscore(recordings[key]['filtered'], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae40ac1-a577-49c2-b8ea-702f742af1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3931fee3-c4fc-4b42-91a1-41ce0d1da894",
   "metadata": {},
   "source": [
    "## We perform (or load) all the spike sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5735eef-2c11-46fd-9106-6bdf62cc676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_kwargs = {'n_jobs': -1, 'progress_bar' :True, 'chunk_memory' : '100M'}\n",
    "si.set_global_job_kwargs(**job_kwargs)\n",
    "erase = True\n",
    "for key in recordings.keys():\n",
    "    folder = base_folder / \"sortings\"\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    folder = base_folder / \"sortings\" / key\n",
    "    if key == '2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_basal':\n",
    "        if folder.exists() and not erase:\n",
    "            recordings[key]['sorting'] = si.read_sorter_folder(folder)\n",
    "        else:\n",
    "            recordings[key]['sorting'] = si.run_sorter('spykingcircus2', recordings[key]['filtered'], \n",
    "                                      folder=folder, verbose=True, apply_preprocessing=False, remove_existing_folder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7ac72-0ba5-43fb-8034-2357f5ecfe82",
   "metadata": {},
   "source": [
    "## We compute (or load) all the waveforms extracted from the spike sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdae62c-6cfb-4f18-8bbe-3e0ef157ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "erase = True\n",
    "for key in recordings.keys():\n",
    "    folder = base_folder / \"analyzers\"\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    folder = base_folder / \"analyzers\" / key\n",
    "    if key == '2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_basal':\n",
    "        if folder.exists() and not erase:\n",
    "            recordings[key]['analyzer'] = si.load_sorting_analyzer(folder)\n",
    "        else:\n",
    "            recordings[key]['analyzer'] = si.create_sorting_analyzer(recordings[key]['sorting'], \n",
    "                                                                     recordings[key]['filtered'], format='binary_folder', \n",
    "                                                                     folder=folder, return_scaled=True, overwrite=True, sparse=True)\n",
    "            recordings[key]['analyzer'].compute(['random_spikes', 'templates', 'noise_levels', \n",
    "                                                 'quality_metrics', 'template_similarity', 'spike_amplitudes'])\n",
    "            recordings[key]['analyzer'].compute('correlograms', window_ms=40, bin_ms=2)\n",
    "            recordings[key]['analyzer'].save_as(folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd24ace-9695-4a3b-9ad1-61ed6b3ea3d4",
   "metadata": {},
   "source": [
    "## We compute the boundaries of the source/target population for every recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20831b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import infer_boundaries\n",
    "for key in recordings.keys():\n",
    "    recordings[key]['boundaries'] = infer_boundaries(recordings[key]['mapping'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790bcb1-18c0-45bd-a096-934e695cce36",
   "metadata": {},
   "source": [
    "## We need to define a quality criteria that will be used in all the following operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0ecd0b0-e61c-4222-92b2-2202077e7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_criteria = 'snr > 3 & isi_violations_ratio < 0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a32ca7-6971-45eb-bec8-e88f4c956b43",
   "metadata": {},
   "source": [
    "## We compute (or load) the quality metrics for all the recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41aa7657-e6c3-459d-8e45-3b3d2d441e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import get_positions\n",
    "for key in recordings.keys():\n",
    "    if key == '2024-03-20_CG_BIN1exp3_MEA22338_v270224_DIV20_MOCK_basal':\n",
    "        sa = recordings[key]['analyzer']\n",
    "        if sa.get_extension('quality_metrics') is None:\n",
    "            sa.compute(['quality_metrics'])\n",
    "        recordings[key]['metrics'] = sa.get_extension('quality_metrics').get_data()\n",
    "        positions, x, y = get_positions(recordings[key])\n",
    "        #recordings[key]['metrics'].insert(0, \"position\", list(positions))\n",
    "        #recordings[key]['metrics'].insert(1, \"x\", list(x))\n",
    "        #recordings[key]['metrics'].insert(2, \"y\", list(y))\n",
    "        path = Path('plots') / \"statistics\"\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        recordings[key]['metrics'].to_excel(path / f\"{key}.xlsx\")\n",
    "        recordings[key]['metrics'].query(quality_criteria).to_excel(path / f\"quality_only_{key}.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
